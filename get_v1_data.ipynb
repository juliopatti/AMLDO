{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a3e3113",
   "metadata": {},
   "source": [
    "# Bibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72cd357a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julio/Documentos/agents_pos/amldo/AMLDO/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import fitz\n",
    "import sys\n",
    "import shutil\n",
    "import unicodedata\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2645ad69",
   "metadata": {},
   "source": [
    "# Extract data\n",
    "- PDF -> TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4686cab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando processamento em lote ---\n",
      "Processando 73 páginas de L14133.pdf...\n",
      "✔️ Salvo (simplificado): data/text/L14133.txt\n",
      "--------------------\n",
      "Processando 26 páginas de L13709.pdf...\n",
      "✔️ Salvo (simplificado): data/text/L13709.txt\n",
      "--------------------\n",
      "Processando 15 páginas de D10024.pdf...\n",
      "✔️ Salvo (simplificado): data/text/D10024.txt\n",
      "--------------------\n",
      "Processando 43 páginas de Lcp123.pdf...\n",
      "✔️ Salvo (simplificado): data/text/Lcp123.txt\n",
      "--------------------\n",
      "\n",
      "--- Processamento concluído ---\n",
      "Total de arquivos salvos: 4\n"
     ]
    }
   ],
   "source": [
    "def processar_pdf_lei(pdf_path: Path, output_dir: Path) -> Path | None:\n",
    "    \"\"\"\n",
    "    Extrai texto de um PDF de lei, limpa headers/footers dinamicamente\n",
    "    e adiciona marcadores estruturais.\n",
    "    \n",
    "    Salva o arquivo .txt no diretório de saída e retorna o caminho.\n",
    "    Retorna None em caso de falha.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Configuração Dinâmica ---\n",
    "    \n",
    "    # Extrai o número base do nome do arquivo (ex: \"14133\" de \"L14133.pdf\")\n",
    "    file_stem = pdf_path.stem\n",
    "    law_number_match = re.search(r'\\d+', file_stem)\n",
    "    \n",
    "    if law_number_match:\n",
    "        # Usa o primeiro grupo de números encontrado (ex: \"14133\", \"13709\", \"10024\", \"123\")\n",
    "        law_number_str = law_number_match.group(0)\n",
    "    else:\n",
    "        # Fallback caso não encontre números (ex: \"minha_lei.pdf\" -> \"minha_lei\")\n",
    "        law_number_str = re.escape(file_stem)\n",
    "\n",
    "    # Define o caminho de saída\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    txt_output_path = output_dir / (pdf_path.stem + \".txt\")\n",
    "\n",
    "    # PADRÕES A REMOVER (header/footer)\n",
    "    RE_DATE_TIME   = re.compile(r\"^\\s*\\d{2}/\\d{2}/\\d{4},\\s*\\d{2}:\\d{2}\\s*$\")\n",
    "    RE_URL         = re.compile(r\"^\\s*https?://www\\.planalto\\.gov\\.br/.*$\", re.I)\n",
    "    # Regex dinâmico: corresponde a \"L 14133\", \"D10024\", \"123\", etc.\n",
    "    RE_LAWCODE     = re.compile(r\"^\\s*[A-Z]*\\s*\" + re.escape(law_number_str) + r\"\\s*$\", re.I)\n",
    "    RE_PAGECOUNT   = re.compile(r\"^\\s*\\d+\\s*/\\s*\\d+\\s*$\")\n",
    "    \n",
    "    REMOVE_LINE_IF_MATCH = [RE_DATE_TIME, RE_URL, RE_LAWCODE, RE_PAGECOUNT]\n",
    "\n",
    "    def is_header_footer(line: str) -> bool:\n",
    "        s = line.strip()\n",
    "        # Usa a lista de regex definida dentro da função 'processar_pdf_lei'\n",
    "        return any(p.match(s) for p in REMOVE_LINE_IF_MATCH)\n",
    "\n",
    "    # DETECTORES HIERÁRQUICOS\n",
    "    RE_TITLE    = re.compile(r\"^\\s*T[ÍI]TULO\\s+[IVXLCDM]+(\\b.*)?$\", re.I)\n",
    "    RE_CHAPTER  = re.compile(r\"^\\s*CAP[ÍI]TULO\\s+[IVXLCDM]+(\\b.*)?$\", re.I)\n",
    "    RE_SECTION  = re.compile(r\"^\\s*(SEÇÃO|SECAO)\\s+[IVXLCDM]+(\\b.*)?$\", re.I)\n",
    "    RE_ARTICLE  = re.compile(r\"^\\s*Art\\.\\s*(\\d+)[\\s\\.-].*$\")\n",
    "    RE_PARAGRAPH= re.compile(r\"^\\s*§\\s*(\\d+)[ºo]?\\b\")\n",
    "\n",
    "    # DETECTORES HIERÁRQUICOS\n",
    "    RE_TITLE      = re.compile(r\"^\\s*T[ÍI]TULO\\s+[IVXLCDM]+(\\b.*)?$\", re.I)\n",
    "    RE_CHAPTER    = re.compile(r\"^\\s*CAP[ÍI]TULO\\s+[IVXLCDM]+(\\b.*)?$\", re.I)\n",
    "    RE_SECTION    = re.compile(r\"^\\s*(SEÇÃO|SECAO)\\s+[IVXLCDM]+(\\b.*)?$\", re.I)\n",
    "    RE_SUBSECTION = re.compile(r\"^\\s*SUBSE[ÇC][ÃA]O\\s+[IVXLCDM]+(\\b.*)?$\", re.I)\n",
    "\n",
    "    # Artigos do tipo: \"Art. 5º\", \"Art 5º\", \"Art. 5º-A\", \"Art. 37-A\", etc.\n",
    "    # Captura o número com sufixos simples (A, B, -A) e ignora pontuação depois.\n",
    "    RE_ARTICLE    = re.compile(\n",
    "        r\"^\\s*Art\\.?\\s*(\\d+(?:[A-Za-z]|-\\s*[A-Za-z])?)\\s*[ºo]?\\b.*$\", re.I\n",
    "    )\n",
    "\n",
    "    # Parágrafos: \"§ 1º\", \"§1º\", etc. (mantido)\n",
    "    RE_PARAGRAPH  = re.compile(r\"^\\s*§\\s*(\\d+)[ºo]?\\b\", re.I)\n",
    "\n",
    "    def maybe_mark_structural(line: str, out: list[str]) -> bool:\n",
    "        \"\"\"Insere marcadores estruturais se a linha corresponder.\"\"\"\n",
    "        s = line.strip()\n",
    "\n",
    "        if RE_TITLE.match(s):\n",
    "            out.append(\"\")                 # separador visual p/ split\n",
    "            out.append(f\"[[TITLE: {s}]]\")\n",
    "            return True\n",
    "\n",
    "        if RE_CHAPTER.match(s):\n",
    "            out.append(\"\")                 # separador visual p/ split\n",
    "            out.append(f\"[[CHAPTER: {s}]]\")\n",
    "            return True\n",
    "\n",
    "        if RE_SECTION.match(s):\n",
    "            out.append(\"\")                 # manter padrão de separador\n",
    "            out.append(f\"[[SECTION: {s}]]\")\n",
    "            return True\n",
    "\n",
    "        if RE_SUBSECTION.match(s):\n",
    "            out.append(\"\")                 # novo nível: SUBSEÇÃO\n",
    "            out.append(f\"[[SUBSECTION: {s}]]\")\n",
    "            return True\n",
    "\n",
    "        m_art = RE_ARTICLE.match(s)\n",
    "        if m_art:\n",
    "            art_num = m_art.group(1).replace(\" \", \"\")  # normaliza \" - A\" -> \"-A\"\n",
    "            out.append(\"\")                 # separador macro\n",
    "            out.append(f\"[[ARTICLE: {art_num}]]\")\n",
    "            out.append(s)                  # mantém a linha original do artigo\n",
    "            return True\n",
    "\n",
    "        m_par = RE_PARAGRAPH.match(s)\n",
    "        if m_par:\n",
    "            out.append(f\"[[PARAGRAPH: §{m_par.group(1)}]]\")\n",
    "            out.append(s)\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    # UTILS\n",
    "    def clean_spaces(s: str) -> str:\n",
    "        s = s.replace(\"\\xa0\", \" \")\n",
    "        s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "        return s.rstrip()\n",
    "\n",
    "    def unhyphenate_softbreaks(text: str) -> str:\n",
    "        \"\"\"Junta palavras quebradas por hífen no fim da linha.\"\"\"\n",
    "        return re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", text)\n",
    "\n",
    "    # --- 3. PIPELINE DE EXECUÇÃO ---\n",
    "    \n",
    "    if not pdf_path.exists():\n",
    "        print(f\"Erro: Arquivo PDF não encontrado em: {pdf_path}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao abrir PDF {pdf_path}: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "        \n",
    "    out_lines: list[str] = []\n",
    "    print(f\"Processando {doc.page_count} páginas de {pdf_path.name}...\")\n",
    "\n",
    "    for page in doc:\n",
    "        page_text = page.get_text()\n",
    "        \n",
    "        for ln in page_text.split('\\n'):\n",
    "            ln_clean = clean_spaces(ln)\n",
    "            \n",
    "            if not ln_clean:\n",
    "                continue\n",
    "            # A função is_header_footer agora usa o RE_LAWCODE dinâmico\n",
    "            if is_header_footer(ln_clean):\n",
    "                continue\n",
    "            \n",
    "            if not maybe_mark_structural(ln_clean, out_lines):\n",
    "                out_lines.append(ln_clean)\n",
    "\n",
    "    doc.close()\n",
    "    \n",
    "    text = \"\\n\".join(out_lines)\n",
    "    text = unhyphenate_softbreaks(text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text) # Consolida quebras de linha\n",
    "    final_text = text.strip()\n",
    "    \n",
    "    # Salva o arquivo de texto final\n",
    "    try:\n",
    "        txt_output_path.write_text(final_text, encoding=\"utf-8\")\n",
    "        print(f\"✔️ Salvo (simplificado): {txt_output_path}\")\n",
    "        return txt_output_path # Retorna o caminho do arquivo salvo\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar arquivo {txt_output_path}: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "\n",
    "INPUT_DIR = Path(\"data/raw\")\n",
    "OUTPUT_DIR = Path(\"data/text\")\n",
    "\n",
    "pdf_files_a_processar = [\n",
    "    INPUT_DIR / 'L14133.pdf',\n",
    "    INPUT_DIR / 'L13709.pdf',\n",
    "    INPUT_DIR / 'D10024.pdf',\n",
    "    INPUT_DIR / 'Lcp123.pdf'\n",
    "]\n",
    "\n",
    "print(\"--- Iniciando processamento em lote ---\")\n",
    "\n",
    "arquivos_salvos = []\n",
    "for pdf_file in pdf_files_a_processar:\n",
    "    caminho_salvo = processar_pdf_lei(pdf_path=pdf_file, output_dir=OUTPUT_DIR)\n",
    "    if caminho_salvo:\n",
    "        arquivos_salvos.append(caminho_salvo)\n",
    "    print(\"-\" * 20) # Separador\n",
    "\n",
    "print(f\"\\n--- Processamento concluído ---\")\n",
    "print(f\"Total de arquivos salvos: {len(arquivos_salvos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f64b8dc",
   "metadata": {},
   "source": [
    "# Tratamento e Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1bc1614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Criando split_docs por TÍTULO (com TÍTULO 0) ---\n",
      "--- Dividindo por títulos: L14133.txt ---\n",
      "  ↳ salvo: data/split_docs/L14133/TITULO_0/titulo_0.txt\n",
      "  ↳ salvo: data/split_docs/L14133/TITULO_I/titulo_1.txt\n",
      "  ↳ salvo: data/split_docs/L14133/TITULO_II/titulo_2.txt\n",
      "  ↳ salvo: data/split_docs/L14133/TITULO_III/titulo_3.txt\n",
      "  ↳ salvo: data/split_docs/L14133/TITULO_IV/titulo_4.txt\n",
      "  ↳ salvo: data/split_docs/L14133/TITULO_V/titulo_5.txt\n",
      "--- Dividindo por títulos: L13709.txt ---\n",
      "  ↳ salvo: data/split_docs/L13709/TITULO_0/titulo_0.txt\n",
      "--- Dividindo por títulos: D10024.txt ---\n",
      "  ↳ salvo: data/split_docs/D10024/TITULO_0/titulo_0.txt\n",
      "--- Dividindo por títulos: Lcp123.txt ---\n",
      "  ↳ salvo: data/split_docs/Lcp123/TITULO_0/titulo_0.txt\n",
      "✔️ Split finalizado em split_docs/ (preâmbulo preservado como TÍTULO 0)\n"
     ]
    }
   ],
   "source": [
    "SPLIT_ROOT = Path(\"data/split_docs\")\n",
    "\n",
    "def slugify_path(text: str, max_len: int = 120) -> str:\n",
    "    \"\"\"\n",
    "    Gera uma pasta segura a partir do [[TITLE: ...]]:\n",
    "      - remove acentos, troca separadores/ilegais por '_', limita tamanho.\n",
    "    \"\"\"\n",
    "    nfkd = unicodedata.normalize(\"NFKD\", text)\n",
    "    ascii_text = \"\".join(ch for ch in nfkd if not unicodedata.combining(ch))\n",
    "    ascii_text = ascii_text.replace(\"[[TITLE:\", \"\").replace(\"]]\", \"\").strip()\n",
    "\n",
    "    ascii_text = ascii_text.replace(os.sep, \"_\").replace(\"\\\\\", \"_\").replace(\"/\", \"_\")\n",
    "    ascii_text = re.sub(r\"[:*?\\\"<>|]\", \"_\", ascii_text)  # caracteres reservados (Windows)\n",
    "    ascii_text = re.sub(r\"\\s+\", \" \", ascii_text).strip().replace(\" \", \"_\")\n",
    "    ascii_text = re.sub(r\"_+\", \"_\", ascii_text)\n",
    "\n",
    "    if len(ascii_text) > max_len:\n",
    "        ascii_text = ascii_text[:max_len].rstrip(\"_\")\n",
    "\n",
    "    return ascii_text or \"TITULO\"\n",
    "\n",
    "def split_by_titles_with_preamble(full_text: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Divide exclusivamente por [[TITLE: ...]], mas preserva o texto ANTES do primeiro título\n",
    "    como ('TITULO_0', <conteudo_pre_titulo>).\n",
    "    Se não houver nenhum título, retorna apenas ('TITULO_0', texto inteiro).\n",
    "    Retorna lista na ordem: [ (id_ou_titulo, conteudo) ]\n",
    "      - Primeiro elemento pode ser ('TITULO_0', ...) se houver preâmbulo.\n",
    "      - Demais elementos usam o título completo como chave.\n",
    "    \"\"\"\n",
    "    lines = full_text.splitlines()\n",
    "    preamble_lines: List[str] = []\n",
    "    parts: List[Tuple[str, List[str]]] = []  # (key, lines)\n",
    "    current_title: str | None = None\n",
    "    current_lines: List[str] = []\n",
    "\n",
    "    found_any_title = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"[[TITLE:\"):\n",
    "            if not found_any_title:\n",
    "                # Primeira ocorrência de título: guarda preâmbulo (se existir)\n",
    "                pre_text = \"\\n\".join(preamble_lines).strip()\n",
    "                if pre_text:\n",
    "                    parts.append((\"TITULO_0\", [pre_text]))\n",
    "                found_any_title = True\n",
    "\n",
    "            # Fechar bloco do título anterior, se houver\n",
    "            if current_title is not None:\n",
    "                parts.append((current_title, current_lines))\n",
    "\n",
    "            current_title = line.strip()  # guarda o título completo\n",
    "            current_lines = []\n",
    "        else:\n",
    "            if not found_any_title:\n",
    "                # Ainda no preâmbulo (antes do primeiro [[TITLE:)\n",
    "                preamble_lines.append(line)\n",
    "            else:\n",
    "                # Dentro de um título já aberto\n",
    "                if current_title is not None:\n",
    "                    current_lines.append(line)\n",
    "\n",
    "    # Fecha o último bloco\n",
    "    if current_title is not None:\n",
    "        parts.append((current_title, current_lines))\n",
    "\n",
    "    # Se nenhum [[TITLE:]] encontrado, tudo é TÍTULO 0\n",
    "    if not found_any_title:\n",
    "        only = full_text.strip()\n",
    "        return [(\"TITULO_0\", only)]\n",
    "\n",
    "    # Converte lines -> str\n",
    "    normalized: List[Tuple[str, str]] = []\n",
    "    for key, ls in parts:\n",
    "        if isinstance(ls, list):\n",
    "            content = \"\\n\".join(ls).strip()\n",
    "        else:\n",
    "            content = str(ls).strip()\n",
    "        if content:\n",
    "            normalized.append((key, content))\n",
    "        else:\n",
    "            # Se for um título sem conteúdo, ainda assim preserva vazio\n",
    "            normalized.append((key, \"\"))\n",
    "\n",
    "    return normalized\n",
    "\n",
    "def salvar_splits_por_titulo(txt_path: Path, split_root: Path = SPLIT_ROOT) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Lê o .txt (gerado por processar_pdf_lei), divide por TÍTULOS e preâmbulo (TÍTULO 0),\n",
    "    e salva em: split_root/<PDF_STEM>/\n",
    "      - TITULO_0/titulo_0.txt (se houver preâmbulo ou nenhum título)\n",
    "      - <PASTA_TITULO_K>/titulo_k.txt para k >= 1\n",
    "    \"\"\"\n",
    "    if not txt_path.exists():\n",
    "        print(f\"[split] Arquivo não encontrado: {txt_path}\", file=sys.stderr)\n",
    "        return []\n",
    "\n",
    "    split_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Pasta do arquivo (um diretório por PDF de origem)\n",
    "    file_dir = split_root / txt_path.stem\n",
    "    # Limpa para refazer sempre do zero\n",
    "    if file_dir.exists():\n",
    "        shutil.rmtree(file_dir)\n",
    "    file_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    full_text = txt_path.read_text(encoding=\"utf-8\")\n",
    "    blocks = split_by_titles_with_preamble(full_text)\n",
    "\n",
    "    saved: List[Path] = []\n",
    "    # Índices: 0 para preâmbulo (TITULO_0), depois 1..n para os títulos\n",
    "    idx = 0\n",
    "    for key, content in blocks:\n",
    "        if key == \"TITULO_0\":\n",
    "            titulo_dir = file_dir / \"TITULO_0\"\n",
    "            titulo_dir.mkdir(parents=True, exist_ok=True)\n",
    "            out_name = f\"titulo_{idx}.txt\"   # idx == 0\n",
    "        else:\n",
    "            titulo_dir = file_dir / slugify_path(key)\n",
    "            titulo_dir.mkdir(parents=True, exist_ok=True)\n",
    "            idx += 1\n",
    "            out_name = f\"titulo_{idx}.txt\"\n",
    "\n",
    "        out_path = titulo_dir / out_name\n",
    "        out_path.write_text(content, encoding=\"utf-8\")\n",
    "        saved.append(out_path)\n",
    "        print(f\"  ↳ salvo: {out_path}\")\n",
    "\n",
    "    return saved\n",
    "\n",
    "# --- Executar split para os arquivos já processados ---\n",
    "print(\"\\n--- Criando split_docs por TÍTULO (com TÍTULO 0) ---\")\n",
    "for txt_file in arquivos_salvos:\n",
    "    print(f\"--- Dividindo por títulos: {txt_file.name} ---\")\n",
    "    _ = salvar_splits_por_titulo(txt_file, SPLIT_ROOT)\n",
    "\n",
    "print(\"✔️ Split finalizado em split_docs/ (preâmbulo preservado como TÍTULO 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e7c0c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Criando split de TÍTULOS e CAPÍTULOS (com 0s de preâmbulo) ---\n",
      "--- Processando: L14133.txt ---\n",
      "  ↳ Título 0 salvo em: data/split_docs/L14133/TITULO_0\n",
      "  ↳ Título 1 salvo em: data/split_docs/L14133/TITULO_I\n",
      "  ↳ Título 2 salvo em: data/split_docs/L14133/TITULO_II\n",
      "  ↳ Título 3 salvo em: data/split_docs/L14133/TITULO_III\n",
      "  ↳ Título 4 salvo em: data/split_docs/L14133/TITULO_IV\n",
      "  ↳ Título 5 salvo em: data/split_docs/L14133/TITULO_V\n",
      "--- Processando: L13709.txt ---\n",
      "  ↳ Título 0 salvo em: data/split_docs/L13709/TITULO_0\n",
      "--- Processando: D10024.txt ---\n",
      "  ↳ Título 0 salvo em: data/split_docs/D10024/TITULO_0\n",
      "--- Processando: Lcp123.txt ---\n",
      "  ↳ Título 0 salvo em: data/split_docs/Lcp123/TITULO_0\n",
      "✔️ Estrutura criada em data/split_docs/\n"
     ]
    }
   ],
   "source": [
    "SPLIT_ROOT = Path(\"data/split_docs\")\n",
    "\n",
    "# --------- slug helpers ---------\n",
    "def _strip_marker(text: str, marker: str) -> str:\n",
    "    return text.replace(marker, \"\").replace(\"]]\", \"\").strip()\n",
    "\n",
    "def _slugify(text: str, max_len: int = 120) -> str:\n",
    "    nfkd = unicodedata.normalize(\"NFKD\", text)\n",
    "    ascii_text = \"\".join(ch for ch in nfkd if not unicodedata.combining(ch))\n",
    "    ascii_text = ascii_text.replace(os.sep, \"_\").replace(\"\\\\\", \"_\").replace(\"/\", \"_\")\n",
    "    ascii_text = re.sub(r\"[:*?\\\"<>|]\", \"_\", ascii_text)\n",
    "    ascii_text = re.sub(r\"\\s+\", \" \", ascii_text).strip().replace(\" \", \"_\")\n",
    "    ascii_text = re.sub(r\"_+\", \"_\", ascii_text)\n",
    "    if len(ascii_text) > max_len:\n",
    "        ascii_text = ascii_text[:max_len].rstrip(\"_\")\n",
    "    return ascii_text or \"UNTITLED\"\n",
    "\n",
    "def slugify_title_folder(title_marker: str) -> str:\n",
    "    # title_marker é o texto completo do marcador [[TITLE: ...]]\n",
    "    base = _strip_marker(title_marker, \"[[TITLE:\")\n",
    "    return _slugify(base) or \"TITULO\"\n",
    "\n",
    "def slugify_chapter_folder(chapter_marker: str) -> str:\n",
    "    # chapter_marker é o texto completo do marcador [[CHAPTER: ...]]\n",
    "    base = _strip_marker(chapter_marker, \"[[CHAPTER:\")\n",
    "    return _slugify(base) or \"CAPITULO\"\n",
    "\n",
    "# --------- splitters ---------\n",
    "def split_by_titles_with_preamble(full_text: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Divide exclusivamente por [[TITLE: ...]], preservando o preâmbulo como ('TITULO_0', ...).\n",
    "    Se não houver [[TITLE: ...]], retorna apenas ('TITULO_0', texto inteiro).\n",
    "    \"\"\"\n",
    "    lines = full_text.splitlines()\n",
    "    preamble_lines: List[str] = []\n",
    "    parts: List[Tuple[str, List[str]]] = []  # (key, lines)\n",
    "    current_title: str | None = None\n",
    "    current_lines: List[str] = []\n",
    "    found_any_title = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"[[TITLE:\"):\n",
    "            if not found_any_title:\n",
    "                pre_text = \"\\n\".join(preamble_lines).strip()\n",
    "                if pre_text:\n",
    "                    parts.append((\"TITULO_0\", [pre_text]))\n",
    "                found_any_title = True\n",
    "            if current_title is not None:\n",
    "                parts.append((current_title, current_lines))\n",
    "            current_title = line.strip()\n",
    "            current_lines = []\n",
    "        else:\n",
    "            if not found_any_title:\n",
    "                preamble_lines.append(line)\n",
    "            else:\n",
    "                if current_title is not None:\n",
    "                    current_lines.append(line)\n",
    "\n",
    "    if current_title is not None:\n",
    "        parts.append((current_title, current_lines))\n",
    "\n",
    "    if not found_any_title:\n",
    "        return [(\"TITULO_0\", full_text.strip())]\n",
    "\n",
    "    normalized: List[Tuple[str, str]] = []\n",
    "    for key, ls in parts:\n",
    "        content = \"\\n\".join(ls).strip()\n",
    "        normalized.append((key, content))\n",
    "    return normalized\n",
    "\n",
    "def split_chapters_with_preamble(title_content: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Dentro do conteúdo de um TÍTULO, divide por [[CHAPTER: ...]].\n",
    "    - Antes do primeiro capítulo => ('CAPITULO_0', ...)\n",
    "    - Depois, ('<CHAPTER_MARKER_COMPLETO>', ...), um por capítulo\n",
    "    Se não houver capítulos, retorna [('CAPITULO_0', title_content)].\n",
    "    \"\"\"\n",
    "    lines = title_content.splitlines()\n",
    "    pre_lines: List[str] = []\n",
    "    parts: List[Tuple[str, List[str]]] = []  # (key, lines)\n",
    "    current_chapter: str | None = None\n",
    "    current_lines: List[str] = []\n",
    "    found_any_chapter = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"[[CHAPTER:\"):\n",
    "            if not found_any_chapter:\n",
    "                pre_text = \"\\n\".join(pre_lines).strip()\n",
    "                parts.append((\"CAPITULO_0\", [pre_text]))  # pode ser vazio; manter pasta 0\n",
    "                found_any_chapter = True\n",
    "            if current_chapter is not None:\n",
    "                parts.append((current_chapter, current_lines))\n",
    "            current_chapter = line.strip()\n",
    "            current_lines = []\n",
    "        else:\n",
    "            if not found_any_chapter:\n",
    "                pre_lines.append(line)\n",
    "            else:\n",
    "                if current_chapter is not None:\n",
    "                    current_lines.append(line)\n",
    "\n",
    "    if current_chapter is not None:\n",
    "        parts.append((current_chapter, current_lines))\n",
    "\n",
    "    if not found_any_chapter:\n",
    "        return [(\"CAPITULO_0\", title_content.strip())]\n",
    "\n",
    "    normalized: List[Tuple[str, str]] = []\n",
    "    for key, ls in parts:\n",
    "        content = \"\\n\".join(ls).strip()\n",
    "        normalized.append((key, content))\n",
    "    return normalized\n",
    "\n",
    "# --------- escritor principal ---------\n",
    "def salvar_splits_por_titulo_e_capitulo(txt_path: Path, split_root: Path = SPLIT_ROOT) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Para cada .txt (já gerado pelo processar_pdf_lei):\n",
    "      1) Cria data/split_docs/<PDF_STEM>/\n",
    "      2) Cria pastas de TÍTULO (incluindo TITULO_0) e salva titulo_<idx>.txt\n",
    "      3) Em cada pasta de TÍTULO, cria 'capitulos/' e subdivide por [[CHAPTER: ...]]:\n",
    "         - CAPITULO_0/capitulo_0.txt (antes do primeiro capítulo)\n",
    "         - <PASTA_CAPITULO_K>/capitulo_K.txt para K>=1\n",
    "    Retorna lista dos caminhos salvos (capítulos e títulos).\n",
    "    \"\"\"\n",
    "    saved: List[Path] = []\n",
    "\n",
    "    if not txt_path.exists():\n",
    "        print(f\"[split] Arquivo não encontrado: {txt_path}\", file=sys.stderr)\n",
    "        return saved\n",
    "\n",
    "    split_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Diretório do arquivo\n",
    "    file_dir = split_root / txt_path.stem\n",
    "    if file_dir.exists():\n",
    "        shutil.rmtree(file_dir)\n",
    "    file_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Lê conteúdo completo\n",
    "    full_text = txt_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    # --- Split por TÍTULO (com TÍTULO 0) ---\n",
    "    title_blocks = split_by_titles_with_preamble(full_text)\n",
    "\n",
    "    title_index = -1  # para TITULO_0 ser 0 ao incrementarmos apenas em títulos \"reais\"\n",
    "    for key, title_content in title_blocks:\n",
    "        if key == \"TITULO_0\":\n",
    "            title_folder = file_dir / \"TITULO_0\"\n",
    "            title_folder.mkdir(parents=True, exist_ok=True)\n",
    "            titulo_file = title_folder / \"titulo_0.txt\"\n",
    "            titulo_file.write_text(title_content, encoding=\"utf-8\")\n",
    "            saved.append(titulo_file)\n",
    "            current_title_idx = 0\n",
    "        else:\n",
    "            title_index += 1\n",
    "            current_title_idx = title_index + 1  # começa em 1\n",
    "            folder_name = slugify_title_folder(key)\n",
    "            title_folder = file_dir / folder_name\n",
    "            title_folder.mkdir(parents=True, exist_ok=True)\n",
    "            titulo_file = title_folder / f\"titulo_{current_title_idx}.txt\"\n",
    "            titulo_file.write_text(title_content, encoding=\"utf-8\")\n",
    "            saved.append(titulo_file)\n",
    "\n",
    "        # --- Split por CAPÍTULO dentro do TÍTULO corrente ---\n",
    "        capitulos_root = title_folder / \"capitulos\"\n",
    "        capitulos_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        chapter_blocks = split_chapters_with_preamble(title_content)\n",
    "\n",
    "        # Índice de capítulos reinicia em cada título, com 0 antes do primeiro capítulo\n",
    "        chapter_idx = -1\n",
    "        for ch_key, ch_content in chapter_blocks:\n",
    "            if ch_key == \"CAPITULO_0\":\n",
    "                ch_folder = capitulos_root / \"CAPITULO_0\"\n",
    "                ch_folder.mkdir(parents=True, exist_ok=True)\n",
    "                ch_file = ch_folder / \"capitulo_0.txt\"\n",
    "                ch_file.write_text(ch_content, encoding=\"utf-8\")\n",
    "                saved.append(ch_file)\n",
    "            else:\n",
    "                chapter_idx += 1\n",
    "                current_ch_idx = chapter_idx + 1  # 1..n\n",
    "                ch_folder = capitulos_root / slugify_chapter_folder(ch_key)\n",
    "                ch_folder.mkdir(parents=True, exist_ok=True)\n",
    "                ch_file = ch_folder / f\"capitulo_{current_ch_idx}.txt\"\n",
    "                ch_file.write_text(ch_content, encoding=\"utf-8\")\n",
    "                saved.append(ch_file)\n",
    "\n",
    "        print(f\"  ↳ Título {current_title_idx} salvo em: {title_folder}\")\n",
    "\n",
    "    return saved\n",
    "\n",
    "# --- Executar para os arquivos já processados ---\n",
    "print(\"\\n--- Criando split de TÍTULOS e CAPÍTULOS (com 0s de preâmbulo) ---\")\n",
    "for txt_file in arquivos_salvos:\n",
    "    print(f\"--- Processando: {txt_file.name} ---\")\n",
    "    _ = salvar_splits_por_titulo_e_capitulo(txt_file, SPLIT_ROOT)\n",
    "\n",
    "print(\"✔️ Estrutura criada em data/split_docs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03414e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Criando split de TÍTULOS, CAPÍTULOS e ARTIGOS (com 0s de preâmbulo) ---\n",
      "--- Processando: L14133.txt ---\n",
      "  ↳ Título 0 salvo em: data/split_docs/L14133/TITULO_0\n",
      "  ↳ Título 1 salvo em: data/split_docs/L14133/TITULO_I\n",
      "  ↳ Título 2 salvo em: data/split_docs/L14133/TITULO_II\n",
      "  ↳ Título 3 salvo em: data/split_docs/L14133/TITULO_III\n",
      "  ↳ Título 4 salvo em: data/split_docs/L14133/TITULO_IV\n",
      "  ↳ Título 5 salvo em: data/split_docs/L14133/TITULO_V\n",
      "--- Processando: L13709.txt ---\n",
      "  ↳ Título 0 salvo em: data/split_docs/L13709/TITULO_0\n",
      "--- Processando: D10024.txt ---\n",
      "  ↳ Título 0 salvo em: data/split_docs/D10024/TITULO_0\n",
      "--- Processando: Lcp123.txt ---\n",
      "  ↳ Título 0 salvo em: data/split_docs/Lcp123/TITULO_0\n",
      "✔️ Estrutura criada em data/split_docs/ (inclui artigos/ com artigo_0 e artigo_<ID>.txt)\n"
     ]
    }
   ],
   "source": [
    "SPLIT_ROOT = Path(\"data/split_docs\")\n",
    "\n",
    "# --------- slug helpers ---------\n",
    "def _strip_marker(text: str, marker: str) -> str:\n",
    "    return text.replace(marker, \"\").replace(\"]]\", \"\").strip()\n",
    "\n",
    "def _slugify(text: str, max_len: int = 120) -> str:\n",
    "    nfkd = unicodedata.normalize(\"NFKD\", text)\n",
    "    ascii_text = \"\".join(ch for ch in nfkd if not unicodedata.combining(ch))\n",
    "    ascii_text = ascii_text.replace(os.sep, \"_\").replace(\"\\\\\", \"_\").replace(\"/\", \"_\")\n",
    "    ascii_text = re.sub(r\"[:*?\\\"<>|]\", \"_\", ascii_text)\n",
    "    ascii_text = re.sub(r\"\\s+\", \" \", ascii_text).strip().replace(\" \", \"_\")\n",
    "    ascii_text = re.sub(r\"_+\", \"_\", ascii_text)\n",
    "    if len(ascii_text) > max_len:\n",
    "        ascii_text = ascii_text[:max_len].rstrip(\"_\")\n",
    "    return ascii_text or \"UNTITLED\"\n",
    "\n",
    "def slugify_title_folder(title_marker: str) -> str:\n",
    "    base = _strip_marker(title_marker, \"[[TITLE:\")\n",
    "    return _slugify(base) or \"TITULO\"\n",
    "\n",
    "def slugify_chapter_folder(chapter_marker: str) -> str:\n",
    "    base = _strip_marker(chapter_marker, \"[[CHAPTER:\")\n",
    "    return _slugify(base) or \"CAPITULO\"\n",
    "\n",
    "def article_id_from_marker(article_marker: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai o ID do artigo do marcador [[ARTICLE: <id>]] e normaliza para uso no nome do arquivo.\n",
    "    Ex.: '5', '5-A', '37B' -> mantém hífen/letras; remove espaços.\n",
    "    \"\"\"\n",
    "    base = _strip_marker(article_marker, \"[[ARTICLE:\")\n",
    "    base = base.replace(\" \", \"\")\n",
    "    # Permitir apenas [A-Za-z0-9_-] para garantir nome de arquivo seguro\n",
    "    base = re.sub(r\"[^A-Za-z0-9_-]\", \"\", base)\n",
    "    return base or \"X\"\n",
    "\n",
    "# --------- splitters ---------\n",
    "def split_by_titles_with_preamble(full_text: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"[[TITLE: ...]] com preâmbulo como ('TITULO_0', ...).\"\"\"\n",
    "    lines = full_text.splitlines()\n",
    "    preamble_lines: List[str] = []\n",
    "    parts: List[Tuple[str, List[str]]] = []\n",
    "    current_title: str | None = None\n",
    "    current_lines: List[str] = []\n",
    "    found_any_title = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"[[TITLE:\"):\n",
    "            if not found_any_title:\n",
    "                pre_text = \"\\n\".join(preamble_lines).strip()\n",
    "                if pre_text or True:  # cria sempre TITULO_0 (pode ser vazio)\n",
    "                    parts.append((\"TITULO_0\", [pre_text]))\n",
    "                found_any_title = True\n",
    "            if current_title is not None:\n",
    "                parts.append((current_title, current_lines))\n",
    "            current_title = line.strip()\n",
    "            current_lines = []\n",
    "        else:\n",
    "            if not found_any_title:\n",
    "                preamble_lines.append(line)\n",
    "            else:\n",
    "                if current_title is not None:\n",
    "                    current_lines.append(line)\n",
    "\n",
    "    if current_title is not None:\n",
    "        parts.append((current_title, current_lines))\n",
    "\n",
    "    if not found_any_title:\n",
    "        return [(\"TITULO_0\", full_text.strip())]\n",
    "\n",
    "    normalized: List[Tuple[str, str]] = []\n",
    "    for key, ls in parts:\n",
    "        content = \"\\n\".join(ls).strip()\n",
    "        normalized.append((key, content))\n",
    "    return normalized\n",
    "\n",
    "def split_chapters_with_preamble(title_content: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"Dentro de um TÍTULO, divide por [[CHAPTER: ...]] com CAPITULO_0 como preâmbulo.\"\"\"\n",
    "    lines = title_content.splitlines()\n",
    "    pre_lines: List[str] = []\n",
    "    parts: List[Tuple[str, List[str]]] = []\n",
    "    current_chapter: str | None = None\n",
    "    current_lines: List[str] = []\n",
    "    found_any_chapter = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"[[CHAPTER:\"):\n",
    "            if not found_any_chapter:\n",
    "                pre_text = \"\\n\".join(pre_lines).strip()\n",
    "                parts.append((\"CAPITULO_0\", [pre_text]))  # preâmbulo (pode ser vazio)\n",
    "                found_any_chapter = True\n",
    "            if current_chapter is not None:\n",
    "                parts.append((current_chapter, current_lines))\n",
    "            current_chapter = line.strip()\n",
    "            current_lines = []\n",
    "        else:\n",
    "            if not found_any_chapter:\n",
    "                pre_lines.append(line)\n",
    "            else:\n",
    "                if current_chapter is not None:\n",
    "                    current_lines.append(line)\n",
    "\n",
    "    if current_chapter is not None:\n",
    "        parts.append((current_chapter, current_lines))\n",
    "\n",
    "    if not found_any_chapter:\n",
    "        return [(\"CAPITULO_0\", title_content.strip())]\n",
    "\n",
    "    normalized: List[Tuple[str, str]] = []\n",
    "    for key, ls in parts:\n",
    "        content = \"\\n\".join(ls).strip()\n",
    "        normalized.append((key, content))\n",
    "    return normalized\n",
    "\n",
    "def split_articles_with_preamble(chapter_content: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Dentro do conteúdo de um CAPÍTULO, divide por [[ARTICLE: <id>]].\n",
    "    - Antes do primeiro artigo => ('ARTIGO_0', ...)\n",
    "    - Cada artigo => ('[[ARTICLE: <id>]]', conteúdo até o próximo)\n",
    "    Se não houver artigos, retorna [('ARTIGO_0', chapter_content)].\n",
    "    \"\"\"\n",
    "    lines = chapter_content.splitlines()\n",
    "    pre_lines: List[str] = []\n",
    "    parts: List[Tuple[str, List[str]]] = []\n",
    "    current_article: str | None = None\n",
    "    current_lines: List[str] = []\n",
    "    found_any_article = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"[[ARTICLE:\"):\n",
    "            if not found_any_article:\n",
    "                pre_text = \"\\n\".join(pre_lines).strip()\n",
    "                parts.append((\"ARTIGO_0\", [pre_text]))  # preâmbulo (pode ser vazio)\n",
    "                found_any_article = True\n",
    "            if current_article is not None:\n",
    "                parts.append((current_article, current_lines))\n",
    "            current_article = line.strip()\n",
    "            current_lines = []\n",
    "        else:\n",
    "            if not found_any_article:\n",
    "                pre_lines.append(line)\n",
    "            else:\n",
    "                if current_article is not None:\n",
    "                    current_lines.append(line)\n",
    "\n",
    "    if current_article is not None:\n",
    "        parts.append((current_article, current_lines))\n",
    "\n",
    "    if not found_any_article:\n",
    "        return [(\"ARTIGO_0\", chapter_content.strip())]\n",
    "\n",
    "    normalized: List[Tuple[str, str]] = []\n",
    "    for key, ls in parts:\n",
    "        content = \"\\n\".join(ls).strip()\n",
    "        normalized.append((key, content))\n",
    "    return normalized\n",
    "\n",
    "# --------- escritor principal ---------\n",
    "def salvar_splits_por_titulo_capitulo_artigos(txt_path: Path, split_root: Path = SPLIT_ROOT) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Para cada .txt (gerado por processar_pdf_lei):\n",
    "      1) Cria data/split_docs/<PDF_STEM>/\n",
    "      2) Cria pastas de TÍTULO (incluindo TITULO_0) e salva titulo_<idx>.txt\n",
    "      3) Em cada TÍTULO, cria 'capitulos/' e subdivide por [[CHAPTER: ...]]:\n",
    "         - CAPITULO_0/capitulo_0.txt (preâmbulo)\n",
    "         - <PASTA_CAPITULO_K>/capitulo_K.txt (K>=1)\n",
    "      4) Em cada CAPÍTULO, cria 'artigos/' e subdivide por [[ARTICLE: <id>]]:\n",
    "         - artigos/artigo_0.txt (antes do primeiro artigo)\n",
    "         - artigos/artigo_<ID>.txt (um por artigo, com <ID> do marcador)\n",
    "    \"\"\"\n",
    "    saved: List[Path] = []\n",
    "\n",
    "    if not txt_path.exists():\n",
    "        print(f\"[split] Arquivo não encontrado: {txt_path}\", file=sys.stderr)\n",
    "        return saved\n",
    "\n",
    "    split_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Diretório do arquivo\n",
    "    file_dir = split_root / txt_path.stem\n",
    "    if file_dir.exists():\n",
    "        shutil.rmtree(file_dir)\n",
    "    file_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Lê conteúdo completo\n",
    "    full_text = txt_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    # --- Split por TÍTULO (com TÍTULO 0) ---\n",
    "    title_blocks = split_by_titles_with_preamble(full_text)\n",
    "\n",
    "    title_index = -1  # para TITULO_0 ser 0\n",
    "    for key, title_content in title_blocks:\n",
    "        if key == \"TITULO_0\":\n",
    "            title_folder = file_dir / \"TITULO_0\"\n",
    "            title_folder.mkdir(parents=True, exist_ok=True)\n",
    "            titulo_file = title_folder / \"titulo_0.txt\"\n",
    "            titulo_file.write_text(title_content, encoding=\"utf-8\")\n",
    "            saved.append(titulo_file)\n",
    "            current_title_idx = 0\n",
    "        else:\n",
    "            title_index += 1\n",
    "            current_title_idx = title_index + 1  # 1..n\n",
    "            folder_name = slugify_title_folder(key)\n",
    "            title_folder = file_dir / folder_name\n",
    "            title_folder.mkdir(parents=True, exist_ok=True)\n",
    "            titulo_file = title_folder / f\"titulo_{current_title_idx}.txt\"\n",
    "            titulo_file.write_text(title_content, encoding=\"utf-8\")\n",
    "            saved.append(titulo_file)\n",
    "\n",
    "        # --- Split por CAPÍTULO dentro do TÍTULO corrente ---\n",
    "        capitulos_root = title_folder / \"capitulos\"\n",
    "        capitulos_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        chapter_blocks = split_chapters_with_preamble(title_content)\n",
    "\n",
    "        chapter_idx = -1\n",
    "        for ch_key, ch_content in chapter_blocks:\n",
    "            if ch_key == \"CAPITULO_0\":\n",
    "                ch_folder = capitulos_root / \"CAPITULO_0\"\n",
    "                ch_folder.mkdir(parents=True, exist_ok=True)\n",
    "                ch_file = ch_folder / \"capitulo_0.txt\"\n",
    "                ch_file.write_text(ch_content, encoding=\"utf-8\")\n",
    "                saved.append(ch_file)\n",
    "                target_chapter_folder = ch_folder\n",
    "            else:\n",
    "                chapter_idx += 1\n",
    "                current_ch_idx = chapter_idx + 1  # 1..n\n",
    "                ch_folder = capitulos_root / slugify_chapter_folder(ch_key)\n",
    "                ch_folder.mkdir(parents=True, exist_ok=True)\n",
    "                ch_file = ch_folder / f\"capitulo_{current_ch_idx}.txt\"\n",
    "                ch_file.write_text(ch_content, encoding=\"utf-8\")\n",
    "                saved.append(ch_file)\n",
    "                target_chapter_folder = ch_folder\n",
    "\n",
    "            # --- Split por ARTIGOS dentro do CAPÍTULO corrente ---\n",
    "            artigos_root = target_chapter_folder / \"artigos\"\n",
    "            artigos_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            article_blocks = split_articles_with_preamble(ch_content)\n",
    "\n",
    "            for a_key, a_content in article_blocks:\n",
    "                if a_key == \"ARTIGO_0\":\n",
    "                    a_file = artigos_root / \"artigo_0.txt\"\n",
    "                else:\n",
    "                    art_id = article_id_from_marker(a_key)\n",
    "                    a_file = artigos_root / f\"artigo_{art_id}.txt\"\n",
    "                a_file.write_text(a_content, encoding=\"utf-8\")\n",
    "                saved.append(a_file)\n",
    "\n",
    "        print(f\"  ↳ Título {current_title_idx} salvo em: {title_folder}\")\n",
    "\n",
    "    return saved\n",
    "\n",
    "# --- Executar para os arquivos já processados ---\n",
    "print(\"\\n--- Criando split de TÍTULOS, CAPÍTULOS e ARTIGOS (com 0s de preâmbulo) ---\")\n",
    "for txt_file in arquivos_salvos:\n",
    "    print(f\"--- Processando: {txt_file.name} ---\")\n",
    "    _ = salvar_splits_por_titulo_capitulo_artigos(txt_file, SPLIT_ROOT)\n",
    "\n",
    "print(\"✔️ Estrutura criada em data/split_docs/ (inclui artigos/ com artigo_0 e artigo_<ID>.txt)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9730aba",
   "metadata": {},
   "source": [
    "# Dataset de artigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e26cf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lei</th>\n",
       "      <th>titulo</th>\n",
       "      <th>capitulo</th>\n",
       "      <th>artigo</th>\n",
       "      <th>path</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D10024</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_0</td>\n",
       "      <td>artigo_0.txt</td>\n",
       "      <td>D10024/TITULO_0/capitulos/CAPITULO_0/artigos/a...</td>\n",
       "      <td>Presidência da República\\nSecretaria-Geral\\nSu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D10024</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_I</td>\n",
       "      <td>artigo_0.txt</td>\n",
       "      <td>D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...</td>\n",
       "      <td>DISPOSIÇÕES PRELIMINARES\\nObjeto e âmbito de a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D10024</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_I</td>\n",
       "      <td>artigo_1.txt</td>\n",
       "      <td>D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...</td>\n",
       "      <td>Art. 1º Este Decreto regulamenta a licitação, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D10024</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_I</td>\n",
       "      <td>artigo_2.txt</td>\n",
       "      <td>D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...</td>\n",
       "      <td>Art. 2º O pregão, na forma eletrônica, é condi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D10024</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_I</td>\n",
       "      <td>artigo_3.txt</td>\n",
       "      <td>D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...</td>\n",
       "      <td>Art. 3º Para fins do disposto neste Decreto, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>Lcp123</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_XIV</td>\n",
       "      <td>artigo_86.txt</td>\n",
       "      <td>Lcp123/TITULO_0/capitulos/CAPITULO_XIV/artigos...</td>\n",
       "      <td>Art. 86. As matérias tratadas nesta Lei Comple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Lcp123</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_XIV</td>\n",
       "      <td>artigo_87-A.txt</td>\n",
       "      <td>Lcp123/TITULO_0/capitulos/CAPITULO_XIV/artigos...</td>\n",
       "      <td>Art. 87-A. Os Poderes Executivos da União, Est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>Lcp123</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_XIV</td>\n",
       "      <td>artigo_87.txt</td>\n",
       "      <td>Lcp123/TITULO_0/capitulos/CAPITULO_XIV/artigos...</td>\n",
       "      <td>Art. 87. O § 1º do art. 3º da Lei Complementar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>Lcp123</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_XIV</td>\n",
       "      <td>artigo_88.txt</td>\n",
       "      <td>Lcp123/TITULO_0/capitulos/CAPITULO_XIV/artigos...</td>\n",
       "      <td>Art. 88. Esta Lei Complementar entra em vigor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>Lcp123</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_XIV</td>\n",
       "      <td>artigo_89.txt</td>\n",
       "      <td>Lcp123/TITULO_0/capitulos/CAPITULO_XIV/artigos...</td>\n",
       "      <td>Art. 89. Ficam revogadas, a partir de 1o de ju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lei    titulo      capitulo           artigo  \\\n",
       "0    D10024  TITULO_0    CAPITULO_0     artigo_0.txt   \n",
       "1    D10024  TITULO_0    CAPITULO_I     artigo_0.txt   \n",
       "2    D10024  TITULO_0    CAPITULO_I     artigo_1.txt   \n",
       "3    D10024  TITULO_0    CAPITULO_I     artigo_2.txt   \n",
       "4    D10024  TITULO_0    CAPITULO_I     artigo_3.txt   \n",
       "..      ...       ...           ...              ...   \n",
       "569  Lcp123  TITULO_0  CAPITULO_XIV    artigo_86.txt   \n",
       "570  Lcp123  TITULO_0  CAPITULO_XIV  artigo_87-A.txt   \n",
       "571  Lcp123  TITULO_0  CAPITULO_XIV    artigo_87.txt   \n",
       "572  Lcp123  TITULO_0  CAPITULO_XIV    artigo_88.txt   \n",
       "573  Lcp123  TITULO_0  CAPITULO_XIV    artigo_89.txt   \n",
       "\n",
       "                                                  path  \\\n",
       "0    D10024/TITULO_0/capitulos/CAPITULO_0/artigos/a...   \n",
       "1    D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...   \n",
       "2    D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...   \n",
       "3    D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...   \n",
       "4    D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...   \n",
       "..                                                 ...   \n",
       "569  Lcp123/TITULO_0/capitulos/CAPITULO_XIV/artigos...   \n",
       "570  Lcp123/TITULO_0/capitulos/CAPITULO_XIV/artigos...   \n",
       "571  Lcp123/TITULO_0/capitulos/CAPITULO_XIV/artigos...   \n",
       "572  Lcp123/TITULO_0/capitulos/CAPITULO_XIV/artigos...   \n",
       "573  Lcp123/TITULO_0/capitulos/CAPITULO_XIV/artigos...   \n",
       "\n",
       "                                                 texto  \n",
       "0    Presidência da República\\nSecretaria-Geral\\nSu...  \n",
       "1    DISPOSIÇÕES PRELIMINARES\\nObjeto e âmbito de a...  \n",
       "2    Art. 1º Este Decreto regulamenta a licitação, ...  \n",
       "3    Art. 2º O pregão, na forma eletrônica, é condi...  \n",
       "4    Art. 3º Para fins do disposto neste Decreto, c...  \n",
       "..                                                 ...  \n",
       "569  Art. 86. As matérias tratadas nesta Lei Comple...  \n",
       "570  Art. 87-A. Os Poderes Executivos da União, Est...  \n",
       "571  Art. 87. O § 1º do art. 3º da Lei Complementar...  \n",
       "572  Art. 88. Esta Lei Complementar entra em vigor ...  \n",
       "573  Art. 89. Ficam revogadas, a partir de 1o de ju...  \n",
       "\n",
       "[574 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT_ROOT = Path(\"data/split_docs\")\n",
    "\n",
    "paths = [p.relative_to(SPLIT_ROOT).as_posix()\n",
    "         for p in SPLIT_ROOT.rglob(\"artigos/*.txt\")]\n",
    "\n",
    "paths = sorted(paths)\n",
    "\n",
    "rows = []\n",
    "for s in paths:\n",
    "    parts = s.split('/')  # [lei, titulo, 'capitulos', capitulo, 'artigos', artigo.txt]\n",
    "    if len(parts) < 6:\n",
    "        continue\n",
    "    # lê o conteúdo do arquivo\n",
    "    txt_path = SPLIT_ROOT / s\n",
    "    texto = txt_path.read_text(encoding='utf-8', errors='ignore')\n",
    "\n",
    "    rows.append({\n",
    "        'lei': parts[0],\n",
    "        'titulo': parts[1],\n",
    "        'capitulo': parts[3],\n",
    "        'artigo': parts[5],   # 'artigo_2.txt' etc.\n",
    "        'path': s,            # caminho após split_docs\n",
    "        'texto': texto,       # conteúdo do arquivo\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows, columns=['lei', 'titulo', 'capitulo', 'artigo', 'path', 'texto'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cba9871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 574/574 [01:56<00:00,  4.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lei</th>\n",
       "      <th>titulo</th>\n",
       "      <th>capitulo</th>\n",
       "      <th>artigo</th>\n",
       "      <th>path</th>\n",
       "      <th>texto</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D10024</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_0</td>\n",
       "      <td>artigo_0.txt</td>\n",
       "      <td>D10024/TITULO_0/capitulos/CAPITULO_0/artigos/a...</td>\n",
       "      <td>Presidência da República\\nSecretaria-Geral\\nSu...</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D10024</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_I</td>\n",
       "      <td>artigo_0.txt</td>\n",
       "      <td>D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...</td>\n",
       "      <td>DISPOSIÇÕES PRELIMINARES\\nObjeto e âmbito de a...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D10024</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_I</td>\n",
       "      <td>artigo_1.txt</td>\n",
       "      <td>D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...</td>\n",
       "      <td>Art. 1º Este Decreto regulamenta a licitação, ...</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D10024</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_I</td>\n",
       "      <td>artigo_2.txt</td>\n",
       "      <td>D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...</td>\n",
       "      <td>Art. 2º O pregão, na forma eletrônica, é condi...</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D10024</td>\n",
       "      <td>TITULO_0</td>\n",
       "      <td>CAPITULO_I</td>\n",
       "      <td>artigo_3.txt</td>\n",
       "      <td>D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...</td>\n",
       "      <td>Art. 3º Para fins do disposto neste Decreto, c...</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lei    titulo    capitulo        artigo  \\\n",
       "0  D10024  TITULO_0  CAPITULO_0  artigo_0.txt   \n",
       "1  D10024  TITULO_0  CAPITULO_I  artigo_0.txt   \n",
       "2  D10024  TITULO_0  CAPITULO_I  artigo_1.txt   \n",
       "3  D10024  TITULO_0  CAPITULO_I  artigo_2.txt   \n",
       "4  D10024  TITULO_0  CAPITULO_I  artigo_3.txt   \n",
       "\n",
       "                                                path  \\\n",
       "0  D10024/TITULO_0/capitulos/CAPITULO_0/artigos/a...   \n",
       "1  D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...   \n",
       "2  D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...   \n",
       "3  D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...   \n",
       "4  D10024/TITULO_0/capitulos/CAPITULO_I/artigos/a...   \n",
       "\n",
       "                                               texto  tokens  \n",
       "0  Presidência da República\\nSecretaria-Geral\\nSu...     239  \n",
       "1  DISPOSIÇÕES PRELIMINARES\\nObjeto e âmbito de a...      15  \n",
       "2  Art. 1º Este Decreto regulamenta a licitação, ...     461  \n",
       "3  Art. 2º O pregão, na forma eletrônica, é condi...     227  \n",
       "4  Art. 3º Para fins do disposto neste Decreto, c...     946  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_ID = \"gemini-2.5-flash-lite\"  # use exatamente o modelo que você vai chamar\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "_model = genai.GenerativeModel(MODEL_ID)\n",
    "\n",
    "def contar_tokens_gemini(texto: str) -> int:\n",
    "    if not texto:\n",
    "        return 0\n",
    "    resp = _model.count_tokens(texto)\n",
    "    # resp.total_tokens existe nas versões recentes; int() para garantir tipo\n",
    "    return int(getattr(resp, \"total_tokens\", 0))\n",
    "\n",
    "# adiciona a coluna\n",
    "df[\"tokens\"] = df[\"texto\"].progress_apply(contar_tokens_gemini)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1530221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>343.698606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>947.902415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>136.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>364.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16130.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tokens\n",
       "count    574.000000\n",
       "mean     343.698606\n",
       "std      947.902415\n",
       "min        4.000000\n",
       "25%       57.000000\n",
       "50%      136.500000\n",
       "75%      364.500000\n",
       "max    16130.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f8e831",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d905d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "df.to_csv(\"data/processed/v1_processed_articles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2cfda7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amldo_kernel",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
